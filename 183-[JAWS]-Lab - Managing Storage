183-[JAWS]-Lab - Managing Storage
AWS Lab: Managing Storage
Lab Overview
Amazon Web Services (AWS) provides multiple ways to manage data on Amazon Elastic Block Store (EBS) volumes. In this lab, you will use the AWS Command Line Interface (AWS CLI) to create snapshots of an EBS volume and configure a scheduler to run Python scripts to delete snapshots. In the challenge section, you will sync the contents of a directory on an EBS volume to an Amazon Simple Storage Service (Amazon S3) bucket using the aws s3 sync command.
Lab Environment

Virtual Private Cloud (VPC): Contains a public subnet.
EC2 Instances:
Command Host: Used to administer AWS resources.
Processor: Used for processing tasks and interacting with EBS volumes and S3 buckets.


Duration: Approximately 45 minutes.

Objectives
By the end of this lab, you will be able to:

Create and maintain snapshots for Amazon EC2 instances.
Use aws s3 sync to copy files from an EBS volume to an S3 bucket.
Use the AWS CLI to manage resources described in this lab.

Accessing the AWS Management Console

Choose Start Lab to launch your lab.
Wait until the Lab Status: ready message appears, then close the Start Lab panel.
Choose AWS to open the AWS Management Console in a new browser tab. The system will automatically log you in.
Tip: If the console doesn't open, check for a browser banner or icon indicating blocked pop-ups. Click it to allow the console.


Arrange the AWS Management Console tab alongside these instructions for easier reference.

Task 1: Creating and Configuring Resources
Task 1.1: Create an S3 Bucket

In the AWS Management Console, search for S3 in the search bar and select it to open the S3 Management Console.
Choose Create bucket.
Configure the following:
Bucket name: Enter a unique name using a combination of characters and numbers (e.g., my-unique-bucket-123). Note this as S3-BUCKET-NAME for later use.
Region: Leave as default.


Scroll down and choose Create bucket.

Task 1.2: Attach Instance Profile to Processor

In the AWS Management Console, search for EC2 and select it to open the EC2 Management Console.
In the navigation pane, choose Instances.
Select the Processor instance.
Choose Actions > Security > Modify IAM role.
From the IAM role dropdown, select S3BucketAccess.
Choose Update IAM role.

Task 2: Taking Snapshots of Your Instance
Task 2.1: Connecting to the Command Host EC2 Instance

In the EC2 Management Console, navigate to Instances.
Select the Command Host instance.
Choose Connect.
On the EC2 Instance Connect tab, choose Connect to open a terminal window.

Task 2.2: Taking an Initial Snapshot

To display the EBS volume ID attached to the Processor instance, run the following command in the EC2 Instance Connect terminal:aws ec2 describe-volumes --filters Name=attachment.instance-id,Values=<INSTANCE-ID> --query 'Volumes[*].VolumeId'


Replace <INSTANCE-ID> with the ID of the Processor instance (e.g., i-0123456789abcdef0).
Note the VolumeId (e.g., vol-0123456789abcdef0) for later use.


To create a snapshot of the volume, run:aws ec2 create-snapshot --volume-id <VOLUME-ID> --description "Initial snapshot"


Replace <VOLUME-ID> with the volume ID retrieved above.


To restart the Processor instance, run:aws ec2 start-instances --instance-ids <INSTANCE-ID>


Replace <INSTANCE-ID> with the Processor instance ID.
Wait a couple of minutes for the instance to reach the running state.



Task 2.3: Scheduling the Creation of Subsequent Snapshots

To schedule a cron job that creates a snapshot every minute, run the following command in the Command Host terminal:
echo "* * * * * aws ec2 create-snapshot --volume-id <VOLUME-ID> --description 'Scheduled snapshot'" | crontab -


Replace <VOLUME-ID> with the volume ID retrieved earlier.
Note: This creates snapshots every minute for testing purposes. In production, adjust the cron schedule as needed (e.g., daily).


To verify the cron job, run:
crontab -l


Run the provided snapshatter_v2.py script to delete old snapshots:
python3.8 snapshatter_v2.py


The script will list deleted snapshots (e.g., Deleting snapshot: snap-0t18a20).



Task 3: Syncing Files to S3
Task 3.1: Downloading and Unzipping Sample Files

Connect to the Processor instance using EC2 Instance Connect (follow the same steps as for Command Host).
Download the sample files:wget https://aws-tc-targetobjects.s3.us-west-2.amazonaws.com/UR-TP-100-RG1AWG-1-124627/1.83-1ab-3MWSmanaging-storage/s3/Files.zip


Unzip the files:unzip Files.zip


This creates a files directory containing File1.txt, File2.txt, and File3.txt.



Task 3.2: Syncing Files

Enable versioning on your S3 bucket:aws s3api put-bucket-versioning --bucket <S3-BUCKET-NAME> --versioning-configuration Status=Enabled


Replace <S3-BUCKET-NAME> with your bucket name.


Sync the files directory to your S3 bucket:aws s3 sync ./files s3://<S3-BUCKET-NAME>/files/


This uploads File1.txt, File2.txt, and File3.txt to the files/ directory in your bucket.


Verify the uploaded files:aws s3 ls s3://<S3-BUCKET-NAME>/files/


Delete File1.txt locally:rm ./files/File1.txt


Sync the directory again with the --delete option to remove File1.txt from the S3 bucket:aws s3 sync ./files s3://<S3-BUCKET-NAME>/files/ --delete


This deletes File1.txt from the bucket.


Verify the deletion:aws s3 ls s3://<S3-BUCKET-NAME>/files/


List previous versions of File1.txt:aws s3api list-object-versions --bucket <S3-BUCKET-NAME> --prefix files/File1.txt


Note the VersionId of the deleted file.


Download the previous version of File1.txt:aws s3api get-object --bucket <S3-BUCKET-NAME> --key files/File1.txt --version-id <VERSION-ID> ./files/File1.txt


Replace <VERSION-ID> with the version ID from the previous step.


Verify the file was restored locally:ls ./files


This should list File1.txt, File2.txt, and File3.txt.


Sync the restored files to the S3 bucket:aws s3 sync ./files s3://<S3-BUCKET-NAME>/files/


Verify the new version in the S3 bucket:aws s3 ls s3://<S3-BUCKET-NAME>/files/



Notes

Replace <S3-BUCKET-NAME>, <INSTANCE-ID>, <VOLUME-ID>, and <VERSION-ID> with the appropriate values from your lab environment.
The snapshatter_v2.py script is assumed to be pre-installed on the Command Host instance.
Ensure the Processor instance has the correct IAM role (S3BucketAccess) to access S3 and EBS resources.
The cron job in Task 2.3 is set to run every minute for testing. Adjust the schedule for production use.
